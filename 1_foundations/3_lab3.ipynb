{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "2106364449 (Home)\n",
      "jamal.hansen@gmail.com\n",
      "www.linkedin.com/in/jamalhansen\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "SQL\n",
      "Risk Management\n",
      "Mentoring\n",
      "Languages\n",
      "English (Native or Bilingual)\n",
      "Certifications\n",
      "Python Kitchen\n",
      "AWS Certified Cloud Practitioner\n",
      "React Complete Guide\n",
      "Certified in Risk and Information\n",
      "Systems Control™ (CRISC)\n",
      "Jamal Hansen\n",
      "Data Scientist\n",
      "San Antonio, Texas, United States\n",
      "Summary\n",
      "Technologist and risk analyst building safe and positive customer\n",
      "interactions through data analysis, risk controls and technology\n",
      "enhancements.\n",
      "Experience\n",
      "JPMorgan Chase & Co.\n",
      "Data Scientist Lead - Vice President\n",
      "May 2023 - Present (2 years 2 months)\n",
      "San Antonio, Texas, United States\n",
      "Using technology to solve problems and answer difficult questions\n",
      "USAA\n",
      "Business Risk and Controls Lead\n",
      "December 2019 - May 2023 (3 years 6 months)\n",
      "San Antonio, Texas Metropolitan Area\n",
      "Chase\n",
      "10 years 10 months\n",
      "Business Process Analyst II\n",
      "March 2016 - December 2019 (3 years 10 months)\n",
      "San Antonio, Tx\n",
      "Identify, document and resolve issues identified in business processes to\n",
      "promote a positive customer experience. \n",
      "Process Specialist\n",
      "February 2015 - March 2016 (1 year 2 months)\n",
      "San Antonio, Tx\n",
      "Build a controlled environment for the operations team and solutions\n",
      "developers; Mentor operations specialists in technical skills to promote career\n",
      "growth and advancement.\n",
      "Change Team Manager\n",
      "January 2014 - February 2015 (1 year 2 months)\n",
      "  Page 1 of 3   \n",
      "Develop and implement a resilient change management process to reduce risk\n",
      "and coordinate activities across multiple locations and processes. \n",
      "Production Support Specialist\n",
      "March 2009 - January 2014 (4 years 11 months)\n",
      "Develop technology based solutions to manage and monitor the business with\n",
      "efficiency and transparency.\n",
      "Washington Mutual\n",
      "6 years 6 months\n",
      "Process Improvement Analyst\n",
      "August 2006 - March 2009 (2 years 8 months)\n",
      "Partner with business leaders to enhance business systems and processes to\n",
      "improve speed, availability and security.\n",
      "Data and Reporting Analyst\n",
      "October 2002 - August 2006 (3 years 11 months)\n",
      "Bothell, Washington\n",
      "Build and distribute key indicator and performance metric reporting for call\n",
      "center leadership and their specialists.\n",
      "Landacorp\n",
      "Software Application Developer\n",
      "May 1996 - June 2002 (6 years 2 months)\n",
      "Chico, California\n",
      "Create and maintain a unified medical management software system for\n",
      "hospitals and insurance companies. \n",
      "Education\n",
      "University of Arizona Global Campus\n",
      "Bachelor's degree, Business Leadership · (January 2021 - August 2022)\n",
      "CSU Chico\n",
      "Business · (1995 - 1998)\n",
      "Cal Poly, San Luis Obispo\n",
      "Computer Engineering · (1991 - 1993)\n",
      "Southern New Hampshire University\n",
      "Master of Business Administration - MBA  · (January 2025)\n",
      "  Page 2 of 3   \n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Jamal Hansen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Jamal Hansen. You are answering questions on Jamal Hansen's website, particularly questions related to Jamal Hansen's career, background, skills and experience. Your responsibility is to represent Jamal Hansen for interactions on the website as faithfully as possible. You are given a summary of Jamal Hansen's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Jamal Hansen. I'm a software engineer and data scientist, and I also have experience with Risk Management. I'm originally from Berkeley, California, but I moved to San Antonio, Texas in 2006.\\nI love all foods, particularly French food, but strangely I'm repelled by mayonaisse unless it is flavored. I'm not allergic, I really enjoy Khoresht i Ghormeh Sabzi, gardening, travel and recently found fishing the Missouri River in Montana.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n2106364449 (Home)\\njamal.hansen@gmail.com\\nwww.linkedin.com/in/jamalhansen\\n(LinkedIn)\\nTop Skills\\nSQL\\nRisk Management\\nMentoring\\nLanguages\\nEnglish (Native or Bilingual)\\nCertifications\\nPython Kitchen\\nAWS Certified Cloud Practitioner\\nReact Complete Guide\\nCertified in Risk and Information\\nSystems Control™ (CRISC)\\nJamal Hansen\\nData Scientist\\nSan Antonio, Texas, United States\\nSummary\\nTechnologist and risk analyst building safe and positive customer\\ninteractions through data analysis, risk controls and technology\\nenhancements.\\nExperience\\nJPMorgan Chase & Co.\\nData Scientist Lead - Vice President\\nMay 2023\\xa0-\\xa0Present\\xa0(2 years 2 months)\\nSan Antonio, Texas, United States\\nUsing technology to solve problems and answer difficult questions\\nUSAA\\nBusiness Risk and Controls Lead\\nDecember 2019\\xa0-\\xa0May 2023\\xa0(3 years 6 months)\\nSan Antonio, Texas Metropolitan Area\\nChase\\n10 years 10 months\\nBusiness Process Analyst II\\nMarch 2016\\xa0-\\xa0December 2019\\xa0(3 years 10 months)\\nSan Antonio, Tx\\nIdentify, document and resolve issues identified in business processes to\\npromote a positive customer experience. \\nProcess Specialist\\nFebruary 2015\\xa0-\\xa0March 2016\\xa0(1 year 2 months)\\nSan Antonio, Tx\\nBuild a controlled environment for the operations team and solutions\\ndevelopers; Mentor operations specialists in technical skills to promote career\\ngrowth and advancement.\\nChange Team Manager\\nJanuary 2014\\xa0-\\xa0February 2015\\xa0(1 year 2 months)\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nDevelop and implement a resilient change management process to reduce risk\\nand coordinate activities across multiple locations and processes. \\nProduction Support Specialist\\nMarch 2009\\xa0-\\xa0January 2014\\xa0(4 years 11 months)\\nDevelop technology based solutions to manage and monitor the business with\\nefficiency and transparency.\\nWashington Mutual\\n6 years 6 months\\nProcess Improvement Analyst\\nAugust 2006\\xa0-\\xa0March 2009\\xa0(2 years 8 months)\\nPartner with business leaders to enhance business systems and processes to\\nimprove speed, availability and security.\\nData and Reporting Analyst\\nOctober 2002\\xa0-\\xa0August 2006\\xa0(3 years 11 months)\\nBothell, Washington\\nBuild and distribute key indicator and performance metric reporting for call\\ncenter leadership and their specialists.\\nLandacorp\\nSoftware Application Developer\\nMay 1996\\xa0-\\xa0June 2002\\xa0(6 years 2 months)\\nChico, California\\nCreate and maintain a unified medical management software system for\\nhospitals and insurance companies. \\nEducation\\nUniversity of Arizona Global Campus\\nBachelor's degree,\\xa0Business Leadership\\xa0·\\xa0(January 2021\\xa0-\\xa0August 2022)\\nCSU Chico\\nBusiness\\xa0·\\xa0(1995\\xa0-\\xa01998)\\nCal Poly, San Luis Obispo\\nComputer Engineering\\xa0·\\xa0(1991\\xa0-\\xa01993)\\nSouthern New Hampshire University\\nMaster of Business Administration - MBA\\xa0\\xa0·\\xa0(January 2025)\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Jamal Hansen.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now, I do not hold any patents. My focus has primarily been on software engineering, data science, and risk management throughout my career. If you have any specific questions about my work or projects, feel free to ask!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='This is a good answer. The agent provides the information requested and sounds professional.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "This response is not acceptable because the agent has answered in a constructed language. The persona is to be professional and engaging, and this does not fit that profile at all.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
